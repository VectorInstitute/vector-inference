export VENV_BASE=/ssd005/projects/llm/vllm-ray-venv/

# API Server URL (host, port) are set automatically
# base on the SLURM job and are written to 
# the file specified at VLLM_BASE_URL_FILENAME
# Model and entrypoint configuration
export VLLM_BASE_URL_FILENAME=~/.vllm_api_base_url
export VLLM_MODEL_NAME=google/gemma-2b-it
export JOB_NAME="vllm/${VLLM_MODEL_NAME}"

# Configurations for Vector cluster
export NUM_GPUS=2
export JOB_CPU_MEMORY="32G"
export JOB_PARTITION="t4v2"
export JOB_GRES="gpu:${NUM_GPUS}"

# Configuration for Narval, 
# where partition is set automatically.
# export NUM_GPUS=2
# export JOB_PARTITION=""
# export JOB_GRES_TYPE="a100"
# export JOB_GRES="gpu:${JOB_GRES_TYPE}:${NUM_GPUS}"

# Configuration for "grappe de calcul Mila",
# specifying partition and GPU via gres.
# export NUM_GPUS=2
# export JOB_GRES_TYPE="80g"
# export JOB_GRES="gpu:${JOB_GRES_TYPE}:${NUM_GPUS}"
# export JOB_PARTITION="main"