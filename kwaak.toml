# This is a a prefilled template for `kwaak`
#
# Several assumptions and defaults have been filled in. For proper usage, please customize the values to your needs.
project_name = "vector-inference"
language = "Python"

## If you are using OpenAI, set the api key here
openai_api_key = "env:OPENAI_API_KEY"


## If you are using Anthropic, set the api key here
#anthropic_api_key = "env:ANTHROPIC_API_KEY"


## Optional: Connect kwaak to github to create PRs, search code, and automatically push to a  remote
github_api_key = "env:GITHUB_TOKEN"


## Optional: Connect kwaak to tavily to enable it to search the web
#tavily_api_key = "env:TAVILY_API_KEY"

## Commands the agent uses for tools
## Kwaak can use tests, coverage, and lints to verify generated code.
## At the moment, the format of the output does not matter.
[commands]
## Optional: Allows an agent to run tests. Recommended.
# Example: test = "cargo test --no-fail-fast --color=never"
#test = "<YOUR TEST COMMAND>"
## Optional: Allows an agent to run coverage. The coverage command should run the tests and output the coverage results to stdout.
# Example: coverage = "cargo llvm-cov --no-clean --summary-only"
#coverage = "<YOUR COVERAGE COMMAND>"
## Optional: Lint and fix command. This command is run after each completion cycle, before committing the code.
# Recommended to use, as it avoids the LLM getting distracted by linting issues
# Example: lint_and_fix = "cargo clippy --fix --allow-dirty --allow-staged && cargo fmt"
#lint_and_fix = "<YOUR LINT AND FIX COMMAND>"

## Git and GitHub configuration
#
## Kwaak can create and update PRs on Github, search github code, and interact with the git repository. This requires a github token.
## If you leave the token empty, kwaak will not create PRs.
[git]
main_branch = "develop"
owner = "VectorInstitute"
repository = "vector-inference"
auto_push_remote = false

## Kwaak uses different LLMs for different tasks. As a rule of thumb, tasks that happen often (like indexing, summarizing) require a small, fast model
## and tasks that happen less often (like completion) can use a larger, more accurate model.
#
## You can overwrite the api key and base url per kind of task if needed.
[llm.indexing]
provider = "OpenAI"
prompt_model = "gpt-4o-mini"
[llm.query]
provider = "OpenAI"
prompt_model = "gpt-4o"
[llm.embedding]
provider = "OpenAI"
embedding_model = "text-embedding-3-large"
## Docker configuration
## kwaak requires a Dockerfile for the tool execution environment.
## Besides the dependencies to run the code, there are several additional dependencies:
## - `git` for interacting with the codebase
## - `rg` (ripgrep) for searching the codebase
## - `fd` (fd) for effective file searching
##
## In the future, an executor is planned that does not have these dependencies, but for now, they are required.
##
## If your project already has a Dockerfile and you want to keep it clean, you can specify a different file to use.
[docker]
dockerfile = "Dockerfile"
