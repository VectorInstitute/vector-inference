models:
  c4ai-command-r-plus-08-2024:
    model_family: c4ai-command-r
    model_variant: plus-08-2024
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 2
    vocab_size: 256000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --pipeline-parallel-size: 2
      --tensor-parallel-size: 4
      --max-model-len: 65536
  c4ai-command-r-08-2024:
    model_family: c4ai-command-r
    model_variant: 08-2024
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 256000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 32768
  CodeLlama-7b-hf:
    model_family: CodeLlama
    model_variant: 7b-hf
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 16384
  CodeLlama-7b-Instruct-hf:
    model_family: CodeLlama
    model_variant: 7b-Instruct-hf
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 16384
  CodeLlama-13b-hf:
    model_family: CodeLlama
    model_variant: 13b-hf
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 16384
  CodeLlama-13b-Instruct-hf:
    model_family: CodeLlama
    model_variant: 13b-Instruct-hf
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 16384
  CodeLlama-34b-hf:
    model_family: CodeLlama
    model_variant: 34b-hf
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 16384
  CodeLlama-34b-Instruct-hf:
    model_family: CodeLlama
    model_variant: 34b-Instruct-hf
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 16384
  CodeLlama-70b-hf:
    model_family: CodeLlama
    model_variant: 70b-hf
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 32016
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 4096
  CodeLlama-70b-Instruct-hf:
    model_family: CodeLlama
    model_variant: 70b-Instruct-hf
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 32016
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 4096
  gemma-2-2b-it:
    model_family: gemma-2
    model_variant: 2b-it
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 256000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  gemma-2-9b:
    model_family: gemma-2
    model_variant: 9b
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 256000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  gemma-2-9b-it:
    model_family: gemma-2
    model_variant: 9b-it
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 256000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  gemma-2-27b:
    model_family: gemma-2
    model_variant: 27b
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 256000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 4096
  gemma-2-27b-it:
    model_family: gemma-2
    model_variant: 27b-it
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 256000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 4096
  Llama-2-7b-hf:
    model_family: Llama-2
    model_variant: 7b-hf
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  Llama-2-7b-chat-hf:
    model_family: Llama-2
    model_variant: 7b-chat-hf
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  Llama-2-13b-hf:
    model_family: Llama-2
    model_variant: 13b-hf
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  Llama-2-13b-chat-hf:
    model_family: Llama-2
    model_variant: 13b-chat-hf
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  Llama-2-70b-hf:
    model_family: Llama-2
    model_variant: 70b-hf
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 4096
  Llama-2-70b-chat-hf:
    model_family: Llama-2
    model_variant: 70b-chat-hf
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 4096
  llava-1.5-7b-hf:
    model_family: llava-1.5
    model_variant: 7b-hf
    model_type: VLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  llava-1.5-13b-hf:
    model_family: llava-1.5
    model_variant: 13b-hf
    model_type: VLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  llava-v1.6-mistral-7b-hf:
    model_family: llava-v1.6
    model_variant: mistral-7b-hf
    model_type: VLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  llava-v1.6-34b-hf:
    model_family: llava-v1.6
    model_variant: 34b-hf
    model_type: VLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 64064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 4096
  Meta-Llama-3-8B:
    model_family: Meta-Llama-3
    model_variant: 8B
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 8192
  Meta-Llama-3-8B-Instruct:
    model_family: Meta-Llama-3
    model_variant: 8B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 8192
  Meta-Llama-3-70B:
    model_family: Meta-Llama-3
    model_variant: 70B
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 8192
  Meta-Llama-3-70B-Instruct:
    model_family: Meta-Llama-3
    model_variant: 70B-Instruct
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 8192
  Meta-Llama-3.1-8B:
    model_family: Meta-Llama-3.1
    model_variant: 8B
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 131072
  Meta-Llama-3.1-8B-Instruct:
    model_family: Meta-Llama-3.1
    model_variant: 8B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 131072
  Meta-Llama-3.1-70B:
    model_family: Meta-Llama-3.1
    model_variant: 70B
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 65536
  Meta-Llama-3.1-70B-Instruct:
    model_family: Meta-Llama-3.1
    model_variant: 70B-Instruct
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 65536
  Meta-Llama-3.1-405B-Instruct:
    model_family: Meta-Llama-3.1
    model_variant: 405B-Instruct
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 8
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --pipeline-parallel-size: 8
      --tensor-parallel-size: 4
      --max-model-len: 16384
  Mistral-7B-Instruct-v0.1:
    model_family: Mistral
    model_variant: 7B-Instruct-v0.1
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  Mistral-7B-Instruct-v0.2:
    model_family: Mistral
    model_variant: 7B-Instruct-v0.2
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  Mistral-7B-v0.3:
    model_family: Mistral
    model_variant: 7B-v0.3
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32768
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  Mistral-7B-Instruct-v0.3:
    model_family: Mistral
    model_variant: 7B-Instruct-v0.3
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32768
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  Mistral-Large-Instruct-2407:
    model_family: Mistral
    model_variant: Large-Instruct-2407
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 2
    vocab_size: 32768
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --pipeline-parallel-size: 2
      --tensor-parallel-size: 4
      --max-model-len: 32768
  Mistral-Large-Instruct-2411:
    model_family: Mistral
    model_variant: Large-Instruct-2411
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 2
    vocab_size: 32768
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --pipeline-parallel-size: 2
      --tensor-parallel-size: 4
      --max-model-len: 32768
  Mixtral-8x7B-Instruct-v0.1:
    model_family: Mixtral
    model_variant: 8x7B-Instruct-v0.1
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 32768
  Mixtral-8x22B-v0.1:
    model_family: Mixtral
    model_variant: 8x22B-v0.1
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 2
    vocab_size: 32768
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --pipeline-parallel-size: 2
      --tensor-parallel-size: 4
      --max-model-len: 65536
  Mixtral-8x22B-Instruct-v0.1:
    model_family: Mixtral
    model_variant: 8x22B-Instruct-v0.1
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 2
    vocab_size: 32768
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --pipeline-parallel-size: 2
      --tensor-parallel-size: 4
      --max-model-len: 65536
  Phi-3-medium-128k-instruct:
    model_family: Phi-3
    model_variant: medium-128k-instruct
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 32064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 131072
  Phi-3-vision-128k-instruct:
    model_family: Phi-3-vision
    model_variant: 128k-instruct
    model_type: VLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 32064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 65536
  Llama-3.1-Nemotron-70B-Instruct-HF:
    model_family: Llama-3.1-Nemotron
    model_variant: 70B-Instruct-HF
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 65536
  Llama-3.2-1B:
    model_family: Llama-3.2
    model_variant: 1B
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 131072
  Llama-3.2-1B-Instruct:
    model_family: Llama-3.2
    model_variant: 1B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 131072
  Llama-3.2-3B:
    model_family: Llama-3.2
    model_variant: 3B
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 131072
  Llama-3.2-3B-Instruct:
    model_family: Llama-3.2
    model_variant: 3B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 131072
  Llama-3.2-11B-Vision:
    model_family: Llama-3.2
    model_variant: 11B-Vision
    model_type: VLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 4096
      --max-num-seqs: 64
      --enforce-eager: true
  Llama-3.2-11B-Vision-Instruct:
    model_family: Llama-3.2
    model_variant: 11B-Vision-Instruct
    model_type: VLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 4096
      --max-num-seqs: 64
      --enforce-eager: true
  Llama-3.2-90B-Vision:
    model_family: Llama-3.2
    model_variant: 90B-Vision
    model_type: VLM
    gpus_per_node: 4
    num_nodes: 2
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 8
      --max-model-len: 4096
      --max-num-seqs: 32
      --enforce-eager: true
  Llama-3.2-90B-Vision-Instruct:
    model_family: Llama-3.2
    model_variant: 90B-Vision-Instruct
    model_type: VLM
    gpus_per_node: 4
    num_nodes: 2
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 8
      --max-model-len: 4096
      --max-num-seqs: 32
      --enforce-eager: true
  Qwen2.5-0.5B-Instruct:
    model_family: Qwen2.5
    model_variant: 0.5B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  Qwen2.5-1.5B-Instruct:
    model_family: Qwen2.5
    model_variant: 1.5B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  Qwen2.5-3B-Instruct:
    model_family: Qwen2.5
    model_variant: 3B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  Qwen2.5-7B-Instruct:
    model_family: Qwen2.5
    model_variant: 7B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  Qwen2.5-14B-Instruct:
    model_family: Qwen2.5
    model_variant: 14B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  Qwen2.5-32B-Instruct:
    model_family: Qwen2.5
    model_variant: 32B-Instruct
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 32768
  Qwen2.5-72B-Instruct:
    model_family: Qwen2.5
    model_variant: 72B-Instruct
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 16384
  Qwen2.5-Math-1.5B-Instruct:
    model_family: Qwen2.5
    model_variant: Math-1.5B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  Qwen2.5-Math-7B-Instruct:
    model_family: Qwen2.5
    model_variant: Math-7B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  Qwen2.5-Math-72B-Instruct:
    model_family: Qwen2.5
    model_variant: Math-72B-Instruct
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 4096
  Qwen2.5-Coder-7B-Instruct:
    model_family: Qwen2.5
    model_variant: Coder-7B-Instruct
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  Qwen2.5-Math-RM-72B:
    model_family: Qwen2.5
    model_variant: Math-RM-72B
    model_type: Reward_Modeling
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 4096
  Qwen2.5-Math-PRM-7B:
    model_family: Qwen2.5
    model_variant: Math-PRM-7B
    model_type: Reward_Modeling
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  QwQ-32B:
    model_family: QwQ
    model_variant: 32B
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 32768
  Pixtral-12B-2409:
    model_family: Pixtral
    model_variant: 12B-2409
    model_type: VLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 131072
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 8192
  e5-mistral-7b-instruct:
    model_family: e5
    model_variant: mistral-7b-instruct
    model_type: Text_Embedding
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 32000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  bge-base-en-v1.5:
    model_family: bge
    model_variant: base-en-v1.5
    model_type: Text_Embedding
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 30522
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 512
  all-MiniLM-L6-v2:
    model_family: all-MiniLM
    model_variant: L6-v2
    model_type: Text_Embedding
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 30522
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 512
  Llama-3.3-70B-Instruct:
    model_family: Llama-3.3
    model_variant: 70B-Instruct
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 65536
  InternVL2_5-26B:
    model_family: InternVL2_5
    model_variant: 26B
    model_type: VLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 92553
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 32768
  InternVL2_5-38B:
    model_family: InternVL2_5
    model_variant: 38B
    model_type: VLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 92553
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 32768
  Aya-Expanse-32B:
    model_family: Aya-Expanse
    model_variant: 32B
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 256000
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 8192
  DeepSeek-R1-Distill-Llama-70B:
    model_family: DeepSeek-R1
    model_variant: Distill-Llama-70B
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --max-model-len: 65536
  DeepSeek-R1-Distill-Llama-8B:
    model_family: DeepSeek-R1
    model_variant: Distill-Llama-8B
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 128256
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 131072
  DeepSeek-R1-Distill-Qwen-32B:
    model_family: DeepSeek-R1
    model_variant: Distill-Qwen-32B
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 65536
  DeepSeek-R1-Distill-Qwen-14B:
    model_family: DeepSeek-R1
    model_variant: Distill-Qwen-14B
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 65536
  DeepSeek-R1-Distill-Qwen-7B:
    model_family: DeepSeek-R1
    model_variant: Distill-Qwen-7B
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 131072
  DeepSeek-R1-Distill-Qwen-1.5B:
    model_family: DeepSeek-R1
    model_variant: Distill-Qwen-1.5B
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 131072
  Phi-3.5-vision-instruct:
    model_family: Phi-3.5-vision
    model_variant: instruct
    model_type: VLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 32064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 65536
  InternVL2_5-8B:
    model_family: InternVL2_5
    model_variant: 8B
    model_type: VLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 92553
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 32768
  glm-4v-9b:
    model_family: glm-4v
    model_variant: 9b
    model_type: VLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 151552
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 8192
  Molmo-7B-D-0924:
    model_family: Molmo
    model_variant: 7B-D-0924
    model_type: VLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 152064
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  deepseek-vl2:
    model_family: deepseek-vl2
    model_type: VLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 129280
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 4096
  deepseek-vl2-small:
    model_family: deepseek-vl2
    model_variant: small
    model_type: VLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 129280
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 4096
  Qwen3-8B:
    model_family: Qwen3
    model_variant: 8B
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 151936
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 40960
  Qwen3-14B:
    model_family: Qwen3
    model_variant: 14B
    model_type: LLM
    gpus_per_node: 1
    num_nodes: 1
    vocab_size: 151936
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --max-model-len: 40960
  Qwen3-32B:
    model_family: Qwen3
    model_variant: 32B
    model_type: LLM
    gpus_per_node: 2
    num_nodes: 1
    vocab_size: 151936
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 2
      --max-model-len: 40960
  gpt-oss-120b:
    model_family: gpt-oss
    model_variant: 120b
    model_type: LLM
    gpus_per_node: 4
    num_nodes: 2
    vocab_size: 201088
    time: 08:00:00
    resource_type: l40s
    vllm_args:
      --tensor-parallel-size: 4
      --pipeline-parallel-size: 2
      --max-model-len: 40960
